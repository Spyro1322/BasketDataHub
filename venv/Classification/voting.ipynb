{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../FeatureEngineering/MetaData/data6_&_odds.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.loc[(df.season <= 2013) & (df.season >= 2007)]\n",
    "valid_data = df.loc[(df.season > 2013) & (df.season < 2016)]\n",
    "test_data = df.loc[df.season >= 2016]\n",
    "full_train_data = pd.concat([train_data, valid_data], axis=0)\n",
    "\n",
    "X, y = train_data.drop(columns=['home_team_wins']), train_data.home_team_wins\n",
    "valid_X, valid_y = valid_data.drop(columns=['home_team_wins']), valid_data.home_team_wins\n",
    "test_X, test_y = test_data.drop(columns=['home_team_wins']), test_data.home_team_wins\n",
    "\n",
    "# Split our data\n",
    "X_train, y_train = train_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), train_data.home_team_wins\n",
    "X_val, y_val = valid_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), valid_data.home_team_wins\n",
    "X_test, y_test = test_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), test_data.home_team_wins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print(\"Training Results: \\n===============================\")\n",
    "    clf_report = classification_report(y_train, y_train_pred)\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
    "    print(f\"Accuracy Score:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Classification Report:\\n{clf_report}\")\n",
    "\n",
    "    print(\"Testing Results: \\n===============================\")\n",
    "    clf_report = classification_report(y_test, y_test_pred)\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
    "    print(f\"Accuracy Score:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Classification Report:\\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Voting Classifier with our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make use of basic models with GridSearchCV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=10, max_features='log2', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train, y_train)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1844  940]\n",
      " [ 601 3515]]\n",
      "Accuracy Score:\n",
      "0.7767\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.71      2784\n",
      "           1       0.79      0.85      0.82      4116\n",
      "\n",
      "    accuracy                           0.78      6900\n",
      "   macro avg       0.77      0.76      0.76      6900\n",
      "weighted avg       0.77      0.78      0.77      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 576  435]\n",
      " [ 306 1103]]\n",
      "Accuracy Score:\n",
      "0.6938\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61      1011\n",
      "           1       0.72      0.78      0.75      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.69      0.68      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=10, max_features='log2', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train, y_train)\n",
    "y_pred_vcs = voting_classifier_soft.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[2047  737]\n",
      " [1290 2826]]\n",
      "Accuracy Score:\n",
      "0.7062\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67      2784\n",
      "           1       0.79      0.69      0.74      4116\n",
      "\n",
      "    accuracy                           0.71      6900\n",
      "   macro avg       0.70      0.71      0.70      6900\n",
      "weighted avg       0.72      0.71      0.71      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[693 318]\n",
      " [447 962]]\n",
      "Accuracy Score:\n",
      "0.6839\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.64      1011\n",
      "           1       0.75      0.68      0.72      1409\n",
      "\n",
      "    accuracy                           0.68      2420\n",
      "   macro avg       0.68      0.68      0.68      2420\n",
      "weighted avg       0.69      0.68      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Feature Selection Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uni = train_data[['diff_curr_win_pct','diff_curr_away_record','odds_home','odds_away','elo_diff']]\n",
    "y_train_uni = y_train\n",
    "\n",
    "X_val_uni = valid_data[['diff_curr_win_pct','diff_curr_away_record','odds_home','odds_away','elo_diff']]\n",
    "y_val_uni = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1000, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=250, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='log2', min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_uni, y_train_uni)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1621 1163]\n",
      " [ 872 3244]]\n",
      "Accuracy Score:\n",
      "0.7051\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61      2784\n",
      "           1       0.74      0.79      0.76      4116\n",
      "\n",
      "    accuracy                           0.71      6900\n",
      "   macro avg       0.69      0.69      0.69      6900\n",
      "weighted avg       0.70      0.71      0.70      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 600  411]\n",
      " [ 342 1067]]\n",
      "Accuracy Score:\n",
      "0.6888\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.61      1011\n",
      "           1       0.72      0.76      0.74      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.68      0.68      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_uni, X_val_uni, y_train_uni, y_val_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=1000, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.3, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=250, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='log2', min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_uni, y_train_uni)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1616 1168]\n",
      " [ 874 3242]]\n",
      "Accuracy Score:\n",
      "0.7041\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61      2784\n",
      "           1       0.74      0.79      0.76      4116\n",
      "\n",
      "    accuracy                           0.70      6900\n",
      "   macro avg       0.69      0.68      0.69      6900\n",
      "weighted avg       0.70      0.70      0.70      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 583  428]\n",
      " [ 318 1091]]\n",
      "Accuracy Score:\n",
      "0.6917\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61      1011\n",
      "           1       0.72      0.77      0.75      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.68      0.68      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_uni, X_val_uni, y_train_uni, y_val_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extra = train_data[['odds_home', 'odds_away', 'home_elo', 'visitor_elo', 'elo_diff',\n",
    "                    'eff_diff', 'eff_visitor', 'top_player_diff', 'diff_win_pct_prev_season',\n",
    "                    'diff_home_record_last_season', 'ROAD_RECORD_home',\n",
    "                    'diff_road_record_last_season', 'diff_win_pct_7_last_games', 'W_PCT_home',\n",
    "                    'W_PCT_away', 'W_PCT_prev_away', 'diff_curr_away_record', 'HOME_RECORD_home', 'diff_curr_home_record',\n",
    "                    'diff_curr_win_pct']]\n",
    "\n",
    "y_train_extra = y_train\n",
    "\n",
    "X_val_extra = valid_data[['odds_home', 'odds_away', 'home_elo', 'visitor_elo', 'elo_diff',\n",
    "                    'eff_diff', 'eff_visitor', 'top_player_diff', 'diff_win_pct_prev_season',\n",
    "                    'diff_home_record_last_season', 'ROAD_RECORD_home',\n",
    "                    'diff_road_record_last_season', 'diff_win_pct_7_last_games', 'W_PCT_home',\n",
    "                    'W_PCT_away', 'W_PCT_prev_away', 'diff_curr_away_record', 'HOME_RECORD_home', 'diff_curr_home_record',\n",
    "                    'diff_curr_win_pct']]\n",
    "\n",
    "y_val_extra = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=100, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='log2', min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_extra, y_train_extra)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1711 1073]\n",
      " [ 727 3389]]\n",
      "Accuracy Score:\n",
      "0.7391\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.66      2784\n",
      "           1       0.76      0.82      0.79      4116\n",
      "\n",
      "    accuracy                           0.74      6900\n",
      "   macro avg       0.73      0.72      0.72      6900\n",
      "weighted avg       0.74      0.74      0.74      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 595  416]\n",
      " [ 317 1092]]\n",
      "Accuracy Score:\n",
      "0.6971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62      1011\n",
      "           1       0.72      0.78      0.75      1409\n",
      "\n",
      "    accuracy                           0.70      2420\n",
      "   macro avg       0.69      0.68      0.68      2420\n",
      "weighted avg       0.69      0.70      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_extra, X_val_extra, y_train_extra, y_val_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True,random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=100, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='log2', min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_extra, y_train_extra)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1715 1069]\n",
      " [ 875 3241]]\n",
      "Accuracy Score:\n",
      "0.7183\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      2784\n",
      "           1       0.75      0.79      0.77      4116\n",
      "\n",
      "    accuracy                           0.72      6900\n",
      "   macro avg       0.71      0.70      0.70      6900\n",
      "weighted avg       0.72      0.72      0.72      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 611  400]\n",
      " [ 333 1076]]\n",
      "Accuracy Score:\n",
      "0.6971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63      1011\n",
      "           1       0.73      0.76      0.75      1409\n",
      "\n",
      "    accuracy                           0.70      2420\n",
      "   macro avg       0.69      0.68      0.69      2420\n",
      "weighted avg       0.69      0.70      0.70      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_extra, X_val_extra, y_train_extra, y_val_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFECV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rcv = train_data[['missing_player_diff','odds_home','odds_away','visitor_elo']]\n",
    "y_train_rcv = y_train\n",
    "\n",
    "X_val_rcv = valid_data[['missing_player_diff','odds_home','odds_away','visitor_elo']]\n",
    "y_val_rcv = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1000, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='auto', min_samples_leaf=5, min_samples_split=10, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_rcv, y_train_rcv)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_rcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1537 1247]\n",
      " [ 732 3384]]\n",
      "Accuracy Score:\n",
      "0.7132\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61      2784\n",
      "           1       0.73      0.82      0.77      4116\n",
      "\n",
      "    accuracy                           0.71      6900\n",
      "   macro avg       0.70      0.69      0.69      6900\n",
      "weighted avg       0.71      0.71      0.71      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 561  450]\n",
      " [ 290 1119]]\n",
      "Accuracy Score:\n",
      "0.6942\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60      1011\n",
      "           1       0.71      0.79      0.75      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.69      0.67      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_rcv, X_val_rcv, y_train_rcv, y_val_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=1000, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='auto', min_samples_leaf=5, min_samples_split=10, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_rcv, y_train_rcv)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_rcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1453 1331]\n",
      " [ 646 3470]]\n",
      "Accuracy Score:\n",
      "0.7135\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.52      0.60      2784\n",
      "           1       0.72      0.84      0.78      4116\n",
      "\n",
      "    accuracy                           0.71      6900\n",
      "   macro avg       0.71      0.68      0.69      6900\n",
      "weighted avg       0.71      0.71      0.70      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 526  485]\n",
      " [ 262 1147]]\n",
      "Accuracy Score:\n",
      "0.6913\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.58      1011\n",
      "           1       0.70      0.81      0.75      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.69      0.67      0.67      2420\n",
      "weighted avg       0.69      0.69      0.68      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_rcv, X_val_rcv, y_train_rcv, y_val_rcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 30\n",
    "pca = PCA(n_components=n_components).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=10, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=250, solver='sgd')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=11, max_features='sqrt', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_pca, y_train)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1898  886]\n",
      " [ 654 3462]]\n",
      "Accuracy Score:\n",
      "0.7768\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      2784\n",
      "           1       0.80      0.84      0.82      4116\n",
      "\n",
      "    accuracy                           0.78      6900\n",
      "   macro avg       0.77      0.76      0.76      6900\n",
      "weighted avg       0.78      0.78      0.78      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 576  435]\n",
      " [ 302 1107]]\n",
      "Accuracy Score:\n",
      "0.6955\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61      1011\n",
      "           1       0.72      0.79      0.75      1409\n",
      "\n",
      "    accuracy                           0.70      2420\n",
      "   macro avg       0.69      0.68      0.68      2420\n",
      "weighted avg       0.69      0.70      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_pca, X_val_pca, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=10, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=250, solver='sgd')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=11, max_features='sqrt', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_pca, y_train)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1788  996]\n",
      " [ 482 3634]]\n",
      "Accuracy Score:\n",
      "0.7858\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71      2784\n",
      "           1       0.78      0.88      0.83      4116\n",
      "\n",
      "    accuracy                           0.79      6900\n",
      "   macro avg       0.79      0.76      0.77      6900\n",
      "weighted avg       0.79      0.79      0.78      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 523  488]\n",
      " [ 276 1133]]\n",
      "Accuracy Score:\n",
      "0.6843\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58      1011\n",
      "           1       0.70      0.80      0.75      1409\n",
      "\n",
      "    accuracy                           0.68      2420\n",
      "   macro avg       0.68      0.66      0.66      2420\n",
      "weighted avg       0.68      0.68      0.68      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_pca, X_val_pca, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lasso = train_data[['odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
    "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
    "              'home_elo']]\n",
    "y_train_lasso = y_train\n",
    "\n",
    "X_val_lasso = valid_data[['odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
    "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
    "              'home_elo']]\n",
    "y_val_lasso = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=11, max_features='auto', min_samples_leaf=4, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_lasso, y_train_lasso)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1733 1051]\n",
      " [ 766 3350]]\n",
      "Accuracy Score:\n",
      "0.7367\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66      2784\n",
      "           1       0.76      0.81      0.79      4116\n",
      "\n",
      "    accuracy                           0.74      6900\n",
      "   macro avg       0.73      0.72      0.72      6900\n",
      "weighted avg       0.73      0.74      0.73      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 600  411]\n",
      " [ 332 1077]]\n",
      "Accuracy Score:\n",
      "0.6930\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62      1011\n",
      "           1       0.72      0.76      0.74      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.68      0.68      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_lasso, X_val_lasso, y_train_lasso, y_val_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True,C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=11, max_features='auto', min_samples_leaf=4, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_lasso, y_train_lasso)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1571 1213]\n",
      " [ 699 3417]]\n",
      "Accuracy Score:\n",
      "0.7229\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.56      0.62      2784\n",
      "           1       0.74      0.83      0.78      4116\n",
      "\n",
      "    accuracy                           0.72      6900\n",
      "   macro avg       0.72      0.70      0.70      6900\n",
      "weighted avg       0.72      0.72      0.72      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 553  458]\n",
      " [ 288 1121]]\n",
      "Accuracy Score:\n",
      "0.6917\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60      1011\n",
      "           1       0.71      0.80      0.75      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.68      0.67      0.67      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_lasso, X_val_lasso, y_train_lasso, y_val_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose less models for the voting procedure, add weights to each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "second_voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [\n",
    "            # ('svm', SVC(C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.2, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(n_neighbors=72)),\n",
    "                  # ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=200, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=11, max_features='auto', min_samples_leaf=4, min_samples_split=8, n_estimators=100)),\n",
    "                  # ('gnb', GaussianNB())\n",
    "                  ],\n",
    "    voting='hard', weights=[2,1,1])\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "second_voting_classifier_hard.fit(X_train_lasso, y_train_lasso)\n",
    "y_pred_vch = second_voting_classifier_hard.predict(X_val_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1752 1032]\n",
      " [ 778 3338]]\n",
      "Accuracy Score:\n",
      "0.7377\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      2784\n",
      "           1       0.76      0.81      0.79      4116\n",
      "\n",
      "    accuracy                           0.74      6900\n",
      "   macro avg       0.73      0.72      0.72      6900\n",
      "weighted avg       0.74      0.74      0.74      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 601  410]\n",
      " [ 319 1090]]\n",
      "Accuracy Score:\n",
      "0.6988\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62      1011\n",
      "           1       0.73      0.77      0.75      1409\n",
      "\n",
      "    accuracy                           0.70      2420\n",
      "   macro avg       0.69      0.68      0.69      2420\n",
      "weighted avg       0.70      0.70      0.70      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(second_voting_classifier_hard, X_train_lasso, X_val_lasso, y_train_lasso, y_val_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SFS Forward Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_for_sfs = train_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
    "                    'W_PCT_away', 'W_PCT_prev_home', 'ROAD_RECORD_prev_home', 'W_PCT_prev_away',\n",
    "                    'HOME_RECORD_prev_away', 'ROAD_RECORD_prev_away', 'WIN_PRCT_home_3g',\n",
    "                    'FT_PCT_home_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'WIN_PRCT_home_7g',\n",
    "                    'FT_PCT_away_7g', 'REB_away_7g', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
    "                    'diff_avg_fg3_pct_home', 'diff_avg_fg_pct_away', 'diff_avg_reb_away',\n",
    "                    'top_players', 'eff', 'eff_visitor', 'G_7days', 'back2back',\n",
    "                    'HG_7days_VISITOR', 'AG_7days_VISITOR', 'G_7days_VISITOR',\n",
    "                    'back2back_visitor', 'missing_players', 'missing_players_visitor',\n",
    "                    'home_elo', 'elo_diff', 'missing_player_diff', 'eff_diff',\n",
    "                    'Home_Last_5_Avg_FG3_PCT_home', 'Home_Last_5_Avg_FG3_PCT_away',\n",
    "                    'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_FT_PCT_away',\n",
    "                    'diff_fg_pct_last_3_games', 'diff_fg3_pct_last_7_games',\n",
    "                    'diff_ft_pct_last_3_games', 'diff_ast_last_3_games',\n",
    "                    'diff_ast_last_7_games', 'diff_win_pct_prev_season',\n",
    "                    'diff_home_record_last_season', 'diff_road_record_last_season',\n",
    "                    'diff_curr_win_pct']]\n",
    "\n",
    "y_train_for_sfs = y_train\n",
    "\n",
    "X_val_for_sfs = valid_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
    "                    'W_PCT_away', 'W_PCT_prev_home', 'ROAD_RECORD_prev_home', 'W_PCT_prev_away',\n",
    "                    'HOME_RECORD_prev_away', 'ROAD_RECORD_prev_away', 'WIN_PRCT_home_3g',\n",
    "                    'FT_PCT_home_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'WIN_PRCT_home_7g',\n",
    "                    'FT_PCT_away_7g', 'REB_away_7g', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
    "                    'diff_avg_fg3_pct_home', 'diff_avg_fg_pct_away', 'diff_avg_reb_away',\n",
    "                    'top_players', 'eff', 'eff_visitor', 'G_7days', 'back2back',\n",
    "                    'HG_7days_VISITOR', 'AG_7days_VISITOR', 'G_7days_VISITOR',\n",
    "                    'back2back_visitor', 'missing_players', 'missing_players_visitor',\n",
    "                    'home_elo', 'elo_diff', 'missing_player_diff', 'eff_diff',\n",
    "                    'Home_Last_5_Avg_FG3_PCT_home', 'Home_Last_5_Avg_FG3_PCT_away',\n",
    "                    'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_FT_PCT_away',\n",
    "                    'diff_fg_pct_last_3_games', 'diff_fg3_pct_last_7_games',\n",
    "                    'diff_ft_pct_last_3_games', 'diff_ast_last_3_games',\n",
    "                    'diff_ast_last_7_games', 'diff_win_pct_prev_season',\n",
    "                    'diff_home_record_last_season', 'diff_road_record_last_season',\n",
    "                    'diff_curr_win_pct']]\n",
    "\n",
    "y_val_for_sfs = y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=200, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=10, max_features='sqrt', min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_for_sfs, y_train_for_sfs)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_for_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1820  964]\n",
      " [ 810 3306]]\n",
      "Accuracy Score:\n",
      "0.7429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67      2784\n",
      "           1       0.77      0.80      0.79      4116\n",
      "\n",
      "    accuracy                           0.74      6900\n",
      "   macro avg       0.73      0.73      0.73      6900\n",
      "weighted avg       0.74      0.74      0.74      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 598  413]\n",
      " [ 331 1078]]\n",
      "Accuracy Score:\n",
      "0.6926\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.59      0.62      1011\n",
      "           1       0.72      0.77      0.74      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.68      0.68      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_for_sfs, X_val_for_sfs, y_train_for_sfs, y_val_for_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=200, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=10, max_features='sqrt', min_samples_leaf=3, min_samples_split=8, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_for_sfs, y_train_for_sfs)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_for_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1770 1014]\n",
      " [ 875 3241]]\n",
      "Accuracy Score:\n",
      "0.7262\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65      2784\n",
      "           1       0.76      0.79      0.77      4116\n",
      "\n",
      "    accuracy                           0.73      6900\n",
      "   macro avg       0.72      0.71      0.71      6900\n",
      "weighted avg       0.72      0.73      0.73      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 604  407]\n",
      " [ 332 1077]]\n",
      "Accuracy Score:\n",
      "0.6946\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62      1011\n",
      "           1       0.73      0.76      0.74      1409\n",
      "\n",
      "    accuracy                           0.69      2420\n",
      "   macro avg       0.69      0.68      0.68      2420\n",
      "weighted avg       0.69      0.69      0.69      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_for_sfs, X_val_for_sfs, y_train_for_sfs, y_val_for_sfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SFS Backwards Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_back_sfs = train_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
    "                     'W_PCT_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
    "                     'ROAD_RECORD_prev_away', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'PTS_away_3g',\n",
    "                     'FG_PCT_away_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'PTS_home_7g',\n",
    "                     'FG_PCT_home_7g', 'AST_home_7g', 'AST_away_7g', 'REB_away_7g',\n",
    "                     'diff_avg_pts_away', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
    "                     'diff_avg_fg3_pct_home', 'top_players', 'top_players_visitor', 'eff_visitor',\n",
    "                     'G_7days', 'back2back', 'HG_7days_VISITOR', 'AG_7days_VISITOR',\n",
    "                     'G_7days_VISITOR', 'back2back_visitor', 'home_elo', 'elo_diff',\n",
    "                     'missing_player_diff', 'eff_diff', 'Home_Last_5_Avg_AST_home',\n",
    "                     'Home_Last_5_Avg_REB_home', 'Home_Last_5_Avg_REB_away',\n",
    "                     'Home_Last_5_Avg_FG3_PCT_away', 'Away_Last_5_Avg_PTS_home',\n",
    "                     'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_AST_home',\n",
    "                     'Away_Last_5_Avg_FT_PCT_away', 'diff_fg3_pct_last_3_games',\n",
    "                     'diff_fg3_pct_last_7_games', 'diff_ft_pct_last_3_games',\n",
    "                     'diff_ast_last_7_games', 'diff_reb_last_3_games',\n",
    "                     'diff_win_pct_3_last_games']]\n",
    "\n",
    "y_train_back_sfs = y_train\n",
    "\n",
    "X_val_back_sfs = valid_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
    "                     'W_PCT_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
    "                     'ROAD_RECORD_prev_away', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'PTS_away_3g',\n",
    "                     'FG_PCT_away_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'PTS_home_7g',\n",
    "                     'FG_PCT_home_7g', 'AST_home_7g', 'AST_away_7g', 'REB_away_7g',\n",
    "                     'diff_avg_pts_away', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
    "                     'diff_avg_fg3_pct_home', 'top_players', 'top_players_visitor', 'eff_visitor',\n",
    "                     'G_7days', 'back2back', 'HG_7days_VISITOR', 'AG_7days_VISITOR',\n",
    "                     'G_7days_VISITOR', 'back2back_visitor', 'home_elo', 'elo_diff',\n",
    "                     'missing_player_diff', 'eff_diff', 'Home_Last_5_Avg_AST_home',\n",
    "                     'Home_Last_5_Avg_REB_home', 'Home_Last_5_Avg_REB_away',\n",
    "                     'Home_Last_5_Avg_FG3_PCT_away', 'Away_Last_5_Avg_PTS_home',\n",
    "                     'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_AST_home',\n",
    "                     'Away_Last_5_Avg_FT_PCT_away', 'diff_fg3_pct_last_3_games',\n",
    "                     'diff_fg3_pct_last_7_games', 'diff_ft_pct_last_3_games',\n",
    "                     'diff_ast_last_7_games', 'diff_reb_last_3_games',\n",
    "                     'diff_win_pct_3_last_games']]\n",
    "\n",
    "y_val_back_sfs = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=250, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='sqrt', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train_back_sfs, y_train_back_sfs)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val_back_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1752 1032]\n",
      " [ 800 3316]]\n",
      "Accuracy Score:\n",
      "0.7345\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66      2784\n",
      "           1       0.76      0.81      0.78      4116\n",
      "\n",
      "    accuracy                           0.73      6900\n",
      "   macro avg       0.72      0.72      0.72      6900\n",
      "weighted avg       0.73      0.73      0.73      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 614  397]\n",
      " [ 332 1077]]\n",
      "Accuracy Score:\n",
      "0.6988\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      1011\n",
      "           1       0.73      0.76      0.75      1409\n",
      "\n",
      "    accuracy                           0.70      2420\n",
      "   macro avg       0.69      0.69      0.69      2420\n",
      "weighted avg       0.70      0.70      0.70      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train_back_sfs, X_val_back_sfs, y_train_back_sfs, y_val_back_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=11)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=250, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=8, max_features='sqrt', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n",
    "\n",
    "\n",
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train_back_sfs, y_train_back_sfs)\n",
    "y_pred_vch = voting_classifier_soft.predict(X_val_back_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1699 1085]\n",
      " [ 862 3254]]\n",
      "Accuracy Score:\n",
      "0.7178\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.64      2784\n",
      "           1       0.75      0.79      0.77      4116\n",
      "\n",
      "    accuracy                           0.72      6900\n",
      "   macro avg       0.71      0.70      0.70      6900\n",
      "weighted avg       0.72      0.72      0.72      6900\n",
      "\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 619  392]\n",
      " [ 333 1076]]\n",
      "Accuracy Score:\n",
      "0.7004\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63      1011\n",
      "           1       0.73      0.76      0.75      1409\n",
      "\n",
      "    accuracy                           0.70      2420\n",
      "   macro avg       0.69      0.69      0.69      2420\n",
      "weighted avg       0.70      0.70      0.70      2420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train_back_sfs, X_val_back_sfs, y_train_back_sfs, y_val_back_sfs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
