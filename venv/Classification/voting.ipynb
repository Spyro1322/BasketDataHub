{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../FeatureEngineering/MetaData/data6_&_odds.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.loc[(df.season <= 2013) & (df.season >= 2007)]\n",
    "valid_data = df.loc[(df.season > 2013) & (df.season < 2016)]\n",
    "test_data = df.loc[df.season >= 2016]\n",
    "full_train_data = pd.concat([train_data, valid_data], axis=0)\n",
    "\n",
    "X, y = train_data.drop(columns=['home_team_wins']), train_data.home_team_wins\n",
    "valid_X, valid_y = valid_data.drop(columns=['home_team_wins']), valid_data.home_team_wins\n",
    "test_X, test_y = test_data.drop(columns=['home_team_wins']), test_data.home_team_wins\n",
    "\n",
    "# Split our data\n",
    "X_train, y_train = train_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), train_data.home_team_wins\n",
    "X_val, y_val = valid_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), valid_data.home_team_wins\n",
    "X_test, y_test = test_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), test_data.home_team_wins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print(\"Training Results: \\n===============================\")\n",
    "    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
    "    print(f\"Accuracy Score:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"Classification Report:\\n{clf_report}\")\n",
    "\n",
    "    print(\"Testing Results: \\n===============================\")\n",
    "    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
    "    print(f\"Accuracy Score:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Classification Report:\\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Voting Classifier with our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make use of basic models with GridSearchCV method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with hard voting\n",
    "voting_classifier_hard = VotingClassifier(\n",
    "    estimators = [('svm', SVC(random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=10, max_features='log2', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='hard')\n",
    "\n",
    "\n",
    "# make predictions with the hard voting model\n",
    "voting_classifier_hard.fit(X_train, y_train)\n",
    "y_pred_vch = voting_classifier_hard.predict(X_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1844  940]\n",
      " [ 596 3520]]\n",
      "Accuracy Score:\n",
      "0.7774\n",
      "Classification Report:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.755738     0.789238  0.777391     0.772488      0.775721\n",
      "recall        0.662356     0.855199  0.777391     0.758778      0.777391\n",
      "f1-score      0.705972     0.820896  0.777391     0.763434      0.774527\n",
      "support    2784.000000  4116.000000  0.777391  6900.000000   6900.000000\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 574  437]\n",
      " [ 309 1100]]\n",
      "Accuracy Score:\n",
      "0.6917\n",
      "Classification Report:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.650057     0.715680  0.691736     0.682868      0.688265\n",
      "recall        0.567755     0.780696  0.691736     0.674225      0.691736\n",
      "f1-score      0.606125     0.746775  0.691736     0.676450      0.688016\n",
      "support    1011.000000  1409.000000  0.691736  2420.000000   2420.000000\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_hard, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a voting classifier with soft voting\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    estimators = [('svm', SVC(probability=True, random_state=42, C=1, gamma=0.0001, kernel='rbf')),\n",
    "                  ('xgb', xgb.XGBClassifier(gamma=0.0, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=100)),\n",
    "                  ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
    "                  ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
    "                  ('rf', RandomForestClassifier(bootstrap=True, max_depth=10, max_features='log2', min_samples_leaf=5, min_samples_split=12, n_estimators=100)),\n",
    "                  ('gnb', GaussianNB())],\n",
    "    voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with the soft voting model\n",
    "voting_classifier_soft.fit(X_train, y_train)\n",
    "y_pred_vcs = voting_classifier_soft.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[1805  979]\n",
      " [ 820 3296]]\n",
      "Accuracy Score:\n",
      "0.7393\n",
      "Classification Report:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.687619     0.770994  0.739275     0.729307      0.737354\n",
      "recall        0.648348     0.800777  0.739275     0.724563      0.739275\n",
      "f1-score      0.667406     0.785604  0.739275     0.726505      0.737914\n",
      "support    2784.000000  4116.000000  0.739275  6900.000000   6900.000000\n",
      "Testing Results: \n",
      "===============================\n",
      "Confusion Matrix:\n",
      "[[ 612  399]\n",
      " [ 334 1075]]\n",
      "Accuracy Score:\n",
      "0.6971\n",
      "Classification Report:\n",
      "                     0            1  accuracy    macro avg  weighted avg\n",
      "precision     0.646934     0.729308  0.697107     0.688121      0.694895\n",
      "recall        0.605341     0.762952  0.697107     0.684147      0.697107\n",
      "f1-score      0.625447     0.745751  0.697107     0.685599      0.695492\n",
      "support    1011.000000  1409.000000  0.697107  2420.000000   2420.000000\n"
     ]
    }
   ],
   "source": [
    "evaluate(voting_classifier_soft, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
