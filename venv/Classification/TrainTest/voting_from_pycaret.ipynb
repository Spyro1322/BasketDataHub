{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lOAFu7qDFJH7"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# use seaborn plotting defaults\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ReIWxcmLFJIB"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data6_&_odds.csv')\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UCMzll6uFJID"
      },
      "outputs": [],
      "source": [
        "train_data = df.loc[(df.season <= 2013) & (df.season >= 2007)]\n",
        "valid_data = df.loc[(df.season > 2013) & (df.season < 2016)]\n",
        "test_data = df.loc[df.season >= 2016]\n",
        "full_train_data = pd.concat([train_data, valid_data], axis=0)\n",
        "\n",
        "X, y = train_data.drop(columns=['home_team_wins']), train_data.home_team_wins\n",
        "valid_X, valid_y = valid_data.drop(columns=['home_team_wins']), valid_data.home_team_wins\n",
        "test_X, test_y = test_data.drop(columns=['home_team_wins']), test_data.home_team_wins\n",
        "\n",
        "# Split our data\n",
        "X_train, y_train = train_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), train_data.home_team_wins\n",
        "X_val, y_val = valid_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), valid_data.home_team_wins\n",
        "X_test, y_test = test_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), test_data.home_team_wins\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_train, X_test, y_train, y_test):\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    print(\"Training Results: \\n===============================\")\n",
        "    clf_report = classification_report(y_train, y_train_pred)\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
        "    print(f\"Accuracy Score:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"Classification Report:\\n{clf_report}\")\n",
        "\n",
        "    print(\"Testing Results: \\n===============================\")\n",
        "    clf_report = classification_report(y_test, y_test_pred)\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
        "    print(f\"Accuracy Score:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(f\"Classification Report:\\n{clf_report}\")"
      ],
      "metadata": {
        "id": "RuUlAExUGMGT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine top 5 Pycaret models to a Voting Classifier "
      ],
      "metadata": {
        "id": "7okaPdA-lvUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BTbEgDizFJIF"
      },
      "outputs": [],
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_hard = VotingClassifier(\n",
        "    estimators = [\n",
        "                  # ('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                  #                           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                  #                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                  #                           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                  #                           random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                  #                           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('nb', GaussianNB(priors=None, var_smoothing=8e-09)),\n",
        "                  ('extra', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=7419, verbose=0, warm_start=False)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                  ('ada', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.3,\n",
        "                   n_estimators=220, random_state=7419)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='hard')\n",
        "\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_hard.fit(X_train, y_train)\n",
        "y_pred_vch = voting_classifier_hard.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRUXSRnvFJII",
        "outputId": "030d343d-3afa-4822-9edc-fe0ac40e08c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1994  790]\n",
            " [ 652 3464]]\n",
            "Accuracy Score:\n",
            "0.7910\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.73      2784\n",
            "           1       0.81      0.84      0.83      4116\n",
            "\n",
            "    accuracy                           0.79      6900\n",
            "   macro avg       0.78      0.78      0.78      6900\n",
            "weighted avg       0.79      0.79      0.79      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[ 598  413]\n",
            " [ 334 1075]]\n",
            "Accuracy Score:\n",
            "0.6913\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.59      0.62      1011\n",
            "           1       0.72      0.76      0.74      1409\n",
            "\n",
            "    accuracy                           0.69      2420\n",
            "   macro avg       0.68      0.68      0.68      2420\n",
            "weighted avg       0.69      0.69      0.69      2420\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate(voting_classifier_hard, X_train, X_val, y_train, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_hard = VotingClassifier(\n",
        "    estimators = [\n",
        "                  # ('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                  #                           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                  #                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                  #                           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                  #                           random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                  #                           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('nb', GaussianNB(priors=None, var_smoothing=8e-09)),\n",
        "                  ('extra', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=7419, verbose=0, warm_start=False)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                  ('ada', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.3,\n",
        "                   n_estimators=220, random_state=7419)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='hard')\n",
        "\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_hard.fit(X_train, y_train)\n",
        "y_pred_vch = voting_classifier_hard.predict(X_test)"
      ],
      "metadata": {
        "id": "OANpgo4gGSOk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(voting_classifier_hard, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWBPI3cFH1zq",
        "outputId": "17e3bcbb-4522-4c54-ef6e-9e50dbd8b5f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1994  790]\n",
            " [ 652 3464]]\n",
            "Accuracy Score:\n",
            "0.7910\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.73      2784\n",
            "           1       0.81      0.84      0.83      4116\n",
            "\n",
            "    accuracy                           0.79      6900\n",
            "   macro avg       0.78      0.78      0.78      6900\n",
            "weighted avg       0.79      0.79      0.79      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1079  856]\n",
            " [ 645 2003]]\n",
            "Accuracy Score:\n",
            "0.6725\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.56      0.59      1935\n",
            "           1       0.70      0.76      0.73      2648\n",
            "\n",
            "    accuracy                           0.67      4583\n",
            "   macro avg       0.66      0.66      0.66      4583\n",
            "weighted avg       0.67      0.67      0.67      4583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_hard = VotingClassifier(\n",
        "    estimators = [('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                                            importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                                            min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                                            n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                                            random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                                            subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='hard')\n",
        "\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_hard.fit(X_train, y_train)\n",
        "y_pred_vch = voting_classifier_hard.predict(X_test)"
      ],
      "metadata": {
        "id": "4YmKh8ojIDAN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(voting_classifier_hard, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF1taVhKINms",
        "outputId": "93760c2c-1251-4d2a-89e3-df9c1245e5b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[2454  330]\n",
            " [ 406 3710]]\n",
            "Accuracy Score:\n",
            "0.8933\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      2784\n",
            "           1       0.92      0.90      0.91      4116\n",
            "\n",
            "    accuracy                           0.89      6900\n",
            "   macro avg       0.89      0.89      0.89      6900\n",
            "weighted avg       0.89      0.89      0.89      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1045  890]\n",
            " [ 623 2025]]\n",
            "Accuracy Score:\n",
            "0.6699\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.54      0.58      1935\n",
            "           1       0.69      0.76      0.73      2648\n",
            "\n",
            "    accuracy                           0.67      4583\n",
            "   macro avg       0.66      0.65      0.65      4583\n",
            "weighted avg       0.67      0.67      0.67      4583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra Trees Classifier Dataset"
      ],
      "metadata": {
        "id": "HGaT7bBlJBFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lasso = train_data[['elo_diff', 'odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
        "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
        "              'home_elo']]\n",
        "y_train_lasso = y_train\n",
        "\n",
        "X_val_lasso = valid_data[['elo_diff', 'odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
        "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
        "              'home_elo']]\n",
        "y_val_lasso = y_val\n",
        "\n",
        "X_test_lasso = test_data[['elo_diff', 'odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
        "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
        "              'home_elo']]\n",
        "y_test_lasso = y_test"
      ],
      "metadata": {
        "id": "_JE8-TOAIjo0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_soft = VotingClassifier(\n",
        "    estimators = [('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                                            importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                                            min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                                            n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                                            random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                                            subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='soft')\n",
        "\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_soft.fit(X_train_lasso, y_train_lasso)\n",
        "y_pred_vch = voting_classifier_soft.predict(X_test_lasso)"
      ],
      "metadata": {
        "id": "tGfY9rfnJF3_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(voting_classifier_soft, X_train_lasso, X_test_lasso, y_train_lasso, y_test_lasso)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mUVgaoNJQ3E",
        "outputId": "7df745c3-19fc-44b8-d378-ce655fae03a3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[2001  783]\n",
            " [ 656 3460]]\n",
            "Accuracy Score:\n",
            "0.7914\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.74      2784\n",
            "           1       0.82      0.84      0.83      4116\n",
            "\n",
            "    accuracy                           0.79      6900\n",
            "   macro avg       0.78      0.78      0.78      6900\n",
            "weighted avg       0.79      0.79      0.79      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1170  765]\n",
            " [ 713 1935]]\n",
            "Accuracy Score:\n",
            "0.6775\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.60      0.61      1935\n",
            "           1       0.72      0.73      0.72      2648\n",
            "\n",
            "    accuracy                           0.68      4583\n",
            "   macro avg       0.67      0.67      0.67      4583\n",
            "weighted avg       0.68      0.68      0.68      4583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_soft = VotingClassifier(\n",
        "    estimators = [\n",
        "                  # ('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                  #                           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                  #                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                  #                           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                  #                           random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                  #                           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('nb', GaussianNB(priors=None, var_smoothing=8e-09)),\n",
        "                  ('extra', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=7419, verbose=0, warm_start=False)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                  ('ada', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.3,\n",
        "                   n_estimators=220, random_state=7419)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='soft')\n",
        "\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_soft.fit(X_train_lasso, y_train_lasso)\n",
        "y_pred_vch = voting_classifier_soft.predict(X_test_lasso)"
      ],
      "metadata": {
        "id": "jlqwxSOU1A99"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(voting_classifier_soft, X_train_lasso, X_test_lasso, y_train_lasso, y_test_lasso)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YelJKMI1Wdg",
        "outputId": "792b4d2e-c28e-4686-cda8-dfec31a45c9d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[2294  490]\n",
            " [ 510 3606]]\n",
            "Accuracy Score:\n",
            "0.8551\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      2784\n",
            "           1       0.88      0.88      0.88      4116\n",
            "\n",
            "    accuracy                           0.86      6900\n",
            "   macro avg       0.85      0.85      0.85      6900\n",
            "weighted avg       0.86      0.86      0.86      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1202  733]\n",
            " [ 738 1910]]\n",
            "Accuracy Score:\n",
            "0.6790\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.62      0.62      1935\n",
            "           1       0.72      0.72      0.72      2648\n",
            "\n",
            "    accuracy                           0.68      4583\n",
            "   macro avg       0.67      0.67      0.67      4583\n",
            "weighted avg       0.68      0.68      0.68      4583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SFS Backwards Dataset"
      ],
      "metadata": {
        "id": "Od8M_9sSl9Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_back_sfs = train_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
        "                     'W_PCT_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
        "                     'ROAD_RECORD_prev_away', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'PTS_away_3g',\n",
        "                     'FG_PCT_away_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'PTS_home_7g',\n",
        "                     'FG_PCT_home_7g', 'AST_home_7g', 'AST_away_7g', 'REB_away_7g',\n",
        "                     'diff_avg_pts_away', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
        "                     'diff_avg_fg3_pct_home', 'top_players', 'top_players_visitor', 'eff_visitor',\n",
        "                     'G_7days', 'back2back', 'HG_7days_VISITOR', 'AG_7days_VISITOR',\n",
        "                     'G_7days_VISITOR', 'back2back_visitor', 'home_elo', 'elo_diff',\n",
        "                     'missing_player_diff', 'eff_diff', 'Home_Last_5_Avg_AST_home',\n",
        "                     'Home_Last_5_Avg_REB_home', 'Home_Last_5_Avg_REB_away',\n",
        "                     'Home_Last_5_Avg_FG3_PCT_away', 'Away_Last_5_Avg_PTS_home',\n",
        "                     'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_AST_home',\n",
        "                     'Away_Last_5_Avg_FT_PCT_away', 'diff_fg3_pct_last_3_games',\n",
        "                     'diff_fg3_pct_last_7_games', 'diff_ft_pct_last_3_games',\n",
        "                     'diff_ast_last_7_games', 'diff_reb_last_3_games',\n",
        "                     'diff_win_pct_3_last_games']]\n",
        "\n",
        "y_train_back_sfs = y_train\n",
        "\n",
        "X_val_back_sfs = valid_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
        "                     'W_PCT_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
        "                     'ROAD_RECORD_prev_away', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'PTS_away_3g',\n",
        "                     'FG_PCT_away_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'PTS_home_7g',\n",
        "                     'FG_PCT_home_7g', 'AST_home_7g', 'AST_away_7g', 'REB_away_7g',\n",
        "                     'diff_avg_pts_away', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
        "                     'diff_avg_fg3_pct_home', 'top_players', 'top_players_visitor', 'eff_visitor',\n",
        "                     'G_7days', 'back2back', 'HG_7days_VISITOR', 'AG_7days_VISITOR',\n",
        "                     'G_7days_VISITOR', 'back2back_visitor', 'home_elo', 'elo_diff',\n",
        "                     'missing_player_diff', 'eff_diff', 'Home_Last_5_Avg_AST_home',\n",
        "                     'Home_Last_5_Avg_REB_home', 'Home_Last_5_Avg_REB_away',\n",
        "                     'Home_Last_5_Avg_FG3_PCT_away', 'Away_Last_5_Avg_PTS_home',\n",
        "                     'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_AST_home',\n",
        "                     'Away_Last_5_Avg_FT_PCT_away', 'diff_fg3_pct_last_3_games',\n",
        "                     'diff_fg3_pct_last_7_games', 'diff_ft_pct_last_3_games',\n",
        "                     'diff_ast_last_7_games', 'diff_reb_last_3_games',\n",
        "                     'diff_win_pct_3_last_games']]\n",
        "\n",
        "y_val_back_sfs = y_val\n",
        "\n",
        "X_test_back_sfs = test_data[['num_possible_outcomes', 'odds_home', 'odds_away', 'HOME_RECORD_home',\n",
        "                     'W_PCT_away', 'W_PCT_prev_away', 'HOME_RECORD_prev_away',\n",
        "                     'ROAD_RECORD_prev_away', 'FT_PCT_home_3g', 'FG3_PCT_home_3g', 'PTS_away_3g',\n",
        "                     'FG_PCT_away_3g', 'FT_PCT_away_3g', 'FG3_PCT_away_3g', 'PTS_home_7g',\n",
        "                     'FG_PCT_home_7g', 'AST_home_7g', 'AST_away_7g', 'REB_away_7g',\n",
        "                     'diff_avg_pts_away', 'diff_avg_ast_home', 'diff_avg_ast_away',\n",
        "                     'diff_avg_fg3_pct_home', 'top_players', 'top_players_visitor', 'eff_visitor',\n",
        "                     'G_7days', 'back2back', 'HG_7days_VISITOR', 'AG_7days_VISITOR',\n",
        "                     'G_7days_VISITOR', 'back2back_visitor', 'home_elo', 'elo_diff',\n",
        "                     'missing_player_diff', 'eff_diff', 'Home_Last_5_Avg_AST_home',\n",
        "                     'Home_Last_5_Avg_REB_home', 'Home_Last_5_Avg_REB_away',\n",
        "                     'Home_Last_5_Avg_FG3_PCT_away', 'Away_Last_5_Avg_PTS_home',\n",
        "                     'Away_Last_5_Avg_FG3_PCT_home', 'Away_Last_5_Avg_AST_home',\n",
        "                     'Away_Last_5_Avg_FT_PCT_away', 'diff_fg3_pct_last_3_games',\n",
        "                     'diff_fg3_pct_last_7_games', 'diff_ft_pct_last_3_games',\n",
        "                     'diff_ast_last_7_games', 'diff_reb_last_3_games',\n",
        "                     'diff_win_pct_3_last_games']]\n",
        "\n",
        "y_test_back_sfs = y_test"
      ],
      "metadata": {
        "id": "XAZAXUwpJXv5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_hard = VotingClassifier(\n",
        "    estimators = [('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                                            importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                                            min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                                            n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                                            random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                                            subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='hard')\n",
        "\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_hard.fit(X_train_back_sfs, y_train_back_sfs)\n",
        "y_pred_vch = voting_classifier_hard.predict(X_test_back_sfs)"
      ],
      "metadata": {
        "id": "A0T129DzmB1j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(voting_classifier_hard, X_train_back_sfs, X_test_back_sfs, y_train_back_sfs, y_test_back_sfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZLvoYICmSId",
        "outputId": "143b3ca3-7acd-475f-8c52-694bd27e8bba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[2316  468]\n",
            " [ 533 3583]]\n",
            "Accuracy Score:\n",
            "0.8549\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82      2784\n",
            "           1       0.88      0.87      0.88      4116\n",
            "\n",
            "    accuracy                           0.85      6900\n",
            "   macro avg       0.85      0.85      0.85      6900\n",
            "weighted avg       0.86      0.85      0.86      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1136  799]\n",
            " [ 712 1936]]\n",
            "Accuracy Score:\n",
            "0.6703\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.59      0.60      1935\n",
            "           1       0.71      0.73      0.72      2648\n",
            "\n",
            "    accuracy                           0.67      4583\n",
            "   macro avg       0.66      0.66      0.66      4583\n",
            "weighted avg       0.67      0.67      0.67      4583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a voting classifier with hard voting\n",
        "voting_classifier_hard = VotingClassifier(\n",
        "    estimators = [\n",
        "                  # ('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                  #                           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                  #                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                  #                           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                  #                           random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                  #                           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "                  ('nb', GaussianNB(priors=None, var_smoothing=8e-09)),\n",
        "                  ('extra', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                     criterion='gini', max_depth=None, max_features='auto',\n",
        "                     max_leaf_nodes=None, max_samples=None,\n",
        "                     min_impurity_decrease=0.0,\n",
        "                     min_samples_leaf=1, min_samples_split=2,\n",
        "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "                     oob_score=False, random_state=7419, verbose=0, warm_start=False)),\n",
        "                  ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                                    learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                                    max_features=None, max_leaf_nodes=None,\n",
        "                                                    min_impurity_decrease=0.0,\n",
        "                                                    min_samples_leaf=1, min_samples_split=2,\n",
        "                                                    min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                                    n_iter_no_change=None,\n",
        "                                                    random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                                    validation_fraction=0.1, verbose=0,\n",
        "                                                    warm_start=False)),\n",
        "                #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "                #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "                  ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                       criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0002,\n",
        "                       min_samples_leaf=3, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                       oob_score=False, random_state=8807, verbose=0,\n",
        "                       warm_start=False)),\n",
        "                  ('ada', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.3,\n",
        "                   n_estimators=220, random_state=7419)),\n",
        "                #   ('gnb', GaussianNB())],\n",
        "                ],          \n",
        "    voting='hard')\n",
        "\n",
        "# make predictions with the hard voting model\n",
        "voting_classifier_hard.fit(X_train_back_sfs, y_train_back_sfs)\n",
        "y_pred_vch = voting_classifier_hard.predict(X_test_back_sfs)"
      ],
      "metadata": {
        "id": "hjgbsP5zm4fA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(voting_classifier_hard, X_train_back_sfs, X_test_back_sfs, y_train_back_sfs, y_test_back_sfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNyhS5ow27qJ",
        "outputId": "6a21279d-23b5-403a-bb95-e20a2a0e784d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1951  833]\n",
            " [ 709 3407]]\n",
            "Accuracy Score:\n",
            "0.7765\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.70      0.72      2784\n",
            "           1       0.80      0.83      0.82      4116\n",
            "\n",
            "    accuracy                           0.78      6900\n",
            "   macro avg       0.77      0.76      0.77      6900\n",
            "weighted avg       0.78      0.78      0.78      6900\n",
            "\n",
            "Testing Results: \n",
            "===============================\n",
            "Confusion Matrix:\n",
            "[[1139  796]\n",
            " [ 703 1945]]\n",
            "Accuracy Score:\n",
            "0.6729\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.59      0.60      1935\n",
            "           1       0.71      0.73      0.72      2648\n",
            "\n",
            "    accuracy                           0.67      4583\n",
            "   macro avg       0.66      0.66      0.66      4583\n",
            "weighted avg       0.67      0.67      0.67      4583\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tq6pP7bd2_SJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    },
    "colab": {
      "name": "voting_from_pycaret.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}