{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacking_from_pycaret.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uMxrn0GM40BV"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# use seaborn plotting defaults\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data6_&_odds.csv')\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "sXBiLojQ5QmO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df.loc[(df.season <= 2013) & (df.season >= 2007)]\n",
        "valid_data = df.loc[(df.season > 2013) & (df.season < 2016)]\n",
        "test_data = df.loc[df.season >= 2016]\n",
        "full_train_data = pd.concat([train_data, valid_data], axis=0)\n",
        "\n",
        "X, y = train_data.drop(columns=['home_team_wins']), train_data.home_team_wins\n",
        "valid_X, valid_y = valid_data.drop(columns=['home_team_wins']), valid_data.home_team_wins\n",
        "test_X, test_y = test_data.drop(columns=['home_team_wins']), test_data.home_team_wins\n",
        "\n",
        "# Split our data\n",
        "X_train, y_train = train_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), train_data.home_team_wins\n",
        "X_val, y_val = valid_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), valid_data.home_team_wins\n",
        "X_test, y_test = test_data.drop(columns=[\"game_date_est\",\"season\",\"game_id\",\"home_team\",\"visitor_team\",\"home_team_id\",\"visitor_team_id\",\"home_team_wins\",\"conference\",\"conference_visitor\"]), test_data.home_team_wins\n"
      ],
      "metadata": {
        "id": "LmX4OXdS5tD2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_train, X_test, y_train, y_test):\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "\n",
        "    print(\"Training Results: \\n===============================\")\n",
        "    clf_report = classification_report(y_train, y_train_pred)\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
        "    print(f\"Accuracy Score:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "    print(f\"Classification Report:\\n{clf_report}\")\n",
        "\n",
        "    print(\"Testing Results: \\n===============================\")\n",
        "    clf_report = classification_report(y_test, y_test_pred)\n",
        "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
        "    print(f\"Accuracy Score:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(f\"Classification Report:\\n{clf_report}\")"
      ],
      "metadata": {
        "id": "QZzxtBTu5xqD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine top 5 Pycaret models to a Stacking Classifier "
      ],
      "metadata": {
        "id": "DwCvpmms54gT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a stacking classifier\n",
        "clf = [\n",
        "                  # ('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                  #                           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                  #                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                  #                           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                  #                           random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                  #                           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "          ('nb', GaussianNB(priors=None, var_smoothing=8e-09)),\n",
        "          ('extra', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "              criterion='gini', max_depth=None, max_features='auto',\n",
        "              max_leaf_nodes=None, max_samples=None,\n",
        "              min_impurity_decrease=0.0,\n",
        "              min_samples_leaf=1, min_samples_split=2,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "              oob_score=False, random_state=7419, verbose=0, warm_start=False)),\n",
        "          ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                            max_features=None, max_leaf_nodes=None,\n",
        "                                            min_impurity_decrease=0.0,\n",
        "                                            min_samples_leaf=1, min_samples_split=2,\n",
        "                                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                            n_iter_no_change=None,\n",
        "                                            random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                            validation_fraction=0.1, verbose=0,\n",
        "                                            warm_start=False)),\n",
        "        #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "        #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "          ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                max_leaf_nodes=None, max_samples=None,\n",
        "                min_impurity_decrease=0.0002,\n",
        "                min_samples_leaf=3, min_samples_split=2,\n",
        "                min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                oob_score=False, random_state=8807, verbose=0,\n",
        "                warm_start=False)),\n",
        "          ('ada', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.3,\n",
        "            n_estimators=220, random_state=7419))\n",
        "        #   ('gnb', GaussianNB())],\n",
        "        ]          \n",
        "\n",
        "mlp = MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=100, solver='lbfgs')\n",
        "\n",
        "\n",
        "# make predictions with the 2-stage stacking model\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=clf, final_estimator=mlp, cv=10, stack_method='auto', n_jobs=-1) \n"
      ],
      "metadata": {
        "id": "giFOeRva51mo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "stacking_model.fit(X_train, y_train)\n",
        "val_score = stacking_model.score(X_val, y_val)\n",
        "\n",
        "preds = stacking_model.predict(X_test)\n",
        "test_score = stacking_model.score(X_test, y_test)\n",
        "\n",
        "target_names = ['home_loss', 'home_win']\n",
        "\n",
        "print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n",
        "print(classification_report(y_test, preds, target_names=target_names))\n",
        "print(\"val score:\", val_score)\n",
        "print(\"test score:\", test_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay7z1EDH7AQb",
        "outputId": "36973a35-2009-4b49-d769-55e34f6858e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Συνολικός χρόνος fit και predict: 253.56390523910522 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   home_loss       0.63      0.55      0.59      1935\n",
            "    home_win       0.70      0.77      0.73      2648\n",
            "\n",
            "    accuracy                           0.67      4583\n",
            "   macro avg       0.66      0.66      0.66      4583\n",
            "weighted avg       0.67      0.67      0.67      4583\n",
            "\n",
            "val score: 0.6995867768595041\n",
            "test score: 0.6735762600916431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso Dataset"
      ],
      "metadata": {
        "id": "Q7KXeJfg7oQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lasso = train_data[['elo_diff', 'odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
        "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
        "              'home_elo']]\n",
        "y_train_lasso = y_train\n",
        "\n",
        "X_val_lasso = valid_data[['elo_diff', 'odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
        "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
        "              'home_elo']]\n",
        "y_val_lasso = y_val\n",
        "\n",
        "\n",
        "X_test_lasso = test_data[['elo_diff', 'odds_away', 'odds_home', 'eff_diff', 'eff_visitor',\n",
        "              'missing_players', 'top_players', 'FT_PCT_home_7g', 'diff_avg_reb_away',\n",
        "              'home_elo']]\n",
        "y_test_lasso = y_test"
      ],
      "metadata": {
        "id": "TnM0tNNl7P79"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a stacking classifier\n",
        "clf = [\n",
        "                  # ('lightgbm', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0, \n",
        "                  #                           importance_type='split', learning_rate=0.1, max_depth=-1,\n",
        "                  #                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
        "                  #                           n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
        "                  #                           random_state=8807, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
        "                  #                           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
        "          ('nb', GaussianNB(priors=None, var_smoothing=8e-09)),\n",
        "          ('extra', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "              criterion='gini', max_depth=None, max_features='auto',\n",
        "              max_leaf_nodes=None, max_samples=None,\n",
        "              min_impurity_decrease=0.0,\n",
        "              min_samples_leaf=1, min_samples_split=2,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
        "              oob_score=False, random_state=7419, verbose=0, warm_start=False)),\n",
        "          ('gbc', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
        "                                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
        "                                            max_features=None, max_leaf_nodes=None,\n",
        "                                            min_impurity_decrease=0.0,\n",
        "                                            min_samples_leaf=1, min_samples_split=2,\n",
        "                                            min_weight_fraction_leaf=0.0, n_estimators=100,\n",
        "                                            n_iter_no_change=None,\n",
        "                                            random_state=8807, subsample=1.0, tol=0.0001,\n",
        "                                            validation_fraction=0.1, verbose=0,\n",
        "                                            warm_start=False)),\n",
        "        #   ('knn', KNeighborsClassifier(leaf_size=1, n_neighbors=13)),\n",
        "        #   ('mlp', MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')),\n",
        "          ('rf', RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',\n",
        "                criterion='entropy', max_depth=10, max_features='sqrt',\n",
        "                max_leaf_nodes=None, max_samples=None,\n",
        "                min_impurity_decrease=0.0002,\n",
        "                min_samples_leaf=3, min_samples_split=2,\n",
        "                min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
        "                oob_score=False, random_state=8807, verbose=0,\n",
        "                warm_start=False)),\n",
        "          ('ada', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=0.3,\n",
        "            n_estimators=220, random_state=7419))\n",
        "        #   ('gnb', GaussianNB())],\n",
        "        ]          \n",
        "\n",
        "mlp = MLPClassifier(alpha=1e-05, hidden_layer_sizes=(20, 10, 5), max_iter=150, solver='lbfgs')\n",
        "\n",
        "\n",
        "# make predictions with the 2-stage stacking model\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=clf, final_estimator=mlp, cv=10, stack_method='auto', n_jobs=-1) \n"
      ],
      "metadata": {
        "id": "QoENI5ou9l3G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "stacking_model.fit(X_train_lasso, y_train_lasso)\n",
        "val_score = stacking_model.score(X_val_lasso, y_val_lasso)\n",
        "\n",
        "preds = stacking_model.predict(X_test_lasso)\n",
        "test_score = stacking_model.score(X_test_lasso, y_test_lasso)\n",
        "\n",
        "target_names = ['home_loss', 'home_win']\n",
        "\n",
        "print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n",
        "print(classification_report(y_test_lasso, preds, target_names=target_names))\n",
        "print(\"val score:\", val_score)\n",
        "print(\"test score:\", test_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWzANbes9uNy",
        "outputId": "167f4604-2cb1-4220-c6a8-61c9dc0c3cfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Συνολικός χρόνος fit και predict: 50.57762837409973 seconds\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   home_loss       0.63      0.56      0.59      1935\n",
            "    home_win       0.70      0.76      0.73      2648\n",
            "\n",
            "    accuracy                           0.68      4583\n",
            "   macro avg       0.67      0.66      0.66      4583\n",
            "weighted avg       0.67      0.68      0.67      4583\n",
            "\n",
            "val score: 0.7008264462809918\n",
            "test score: 0.6751036439013747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oitqh-Ek9163"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}